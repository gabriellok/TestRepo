{
    "nbformat": 4, 
    "cells": [
        {
            "source": "<table style=\"border: none\" align=\"left\">\n   <tr style=\"border: none\">\n      <th style=\"border: none\"><font face=\"verdana\" size=\"5\" color=\"black\"><b>Recognition of hand-written digits with IBM Watson Machine Learning</b></th>\n      <th style=\"border: none\"><img src=\"https://github.com/pmservice/customer-satisfaction-prediction/blob/master/app/static/images/ml_icon_gray.png?raw=true\" alt=\"Watson Machine Learning icon\" height=\"40\" width=\"40\"></th>\n   </tr>\n   <tr style=\"border: none\">\n       <th style=\"border: none\"><img src=\"https://github.com/pmservice/wml-sample-models/raw/master/scikit-learn/hand-written-digits-recognition/images/numbers_banner-04.png\" width=\"600\" alt=\"Icon\"> </th>\n   </tr>\n</table>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "This notebook contains steps and code to retrieve data from the IBM Data Science Experience Community, create a predictive model, and start scoring new data. This notebook introduces commands for retrieving, cleaning, and exploring data as well as pipeline creation, model training, model persistance to the Watson Machine Learning repository, model deployment, and scoring.\n\nSome familiarity with Python is helpful. This notebook uses Python 3.5 and scikit-learn 0.17 package.\n\nYou will use a toy dataset available from the [scikit-learn](http://scikit-learn.org/stable/index.html) Web site, **sklearn.datasets.load_digits**, which contains hand-written digits images. Use the toy dataset to recognize hand-written digits. Refer to the [Citations](#citations) for information about use of these images and scikit-learn modules.\n\n## Learning goals\n\nThe learning goals of this notebook are:\n\n-  Loa\n-  Prepare data for training and evaluation.\n-  Create a scikit-learn machine learning pipeline.\n-  Train and evaluate a model.\n-  Persist a pipeline and model in the Watson Machine Learning repository.\n-  Deploy a model for online scoring using the Wastson Machine Learning API.\n-  Score sample scoring data using the Watson Machine Learning API.\n-  Explore and visualize prediction result using the matplotlib package.\n\n\n## Contents\n\nThis notebook contains the following parts:\n\n1.\t[Setup](#setup)\n2.\t[Load and explore data](#load)\n3.\t[Create a scikit-learn model](#model)\n4.\t[Persist the model](#persistence)\n5.\t[Predict locally and visualize](#visualization)\n6.\t[Deploy and score in the cloud](#scoring)\n7.\t[Summary and next steps](#summary)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id=\"setup\"></a>\n## 1. Setup\n\nBefore you use the sample code in this notebook, you must perform the following setup task:\n\n-  Create a [Watson Machine Learning Service](https://console.ng.bluemix.net/catalog/services/ibm-watson-machine-learning/) instance (a free plan is offered). ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id=\"load\"></a>\n## 2. Load and explore data", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "In this section you will load the data from scikit-learn toy datasets and perform a basic exploration.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "**Example**: First, you need to install required packages. You can do it by running the following code. Run it only one time.<BR><BR>\n!pip install sklearn --user <BR>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "from sklearn import datasets\n\ndigits = datasets.load_digits()"
        }, 
        {
            "source": "The data set consists of 8x8 pixel images of hand-written digits. In the following step you will plot the first 5 images using the **matplotlib** library.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "%matplotlib inline\nimport matplotlib.pyplot as plt\n\nimages_number = 5\nimages_and_labels = list(zip(digits.images, digits.target))\n\nfor i, (image, label) in enumerate(images_and_labels[:images_number]):\n    plt.subplot(2, images_number, i + 1)\n    plt.axis('off')\n    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n    plt.title('%i' % label)"
        }, 
        {
            "source": "Let's display the first-digit data and label it using the `data` and `target` methods.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "print(digits.data[0])"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "digits.target[0]"
        }, 
        {
            "source": "In next step you will count all the samples.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "samples_count = len(digits.images)\nprint(\"Number of samples: \" + str(samples_count))"
        }, 
        {
            "source": "<a id=\"model\"></a>\n## 3. Create a scikit-learn machine learning model\n\nIn this section you will learn how to prepare data, create a scikit-learn machine learning pipeline, and train a model.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### 3.1: Prepare data\n\nIn this subsection you will split your data into train, test, and score data sets.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "train_data = digits.data[: int(0.7*samples_count)]\ntrain_labels = digits.target[: int(0.7*samples_count)]\n\ntest_data = digits.data[int(0.7*samples_count): int(0.9*samples_count)]\ntest_labels = digits.target[int(0.7*samples_count): int(0.9*samples_count)]\n\nscore_data = digits.data[int(0.9*samples_count): ]\n\n\nprint(\"Number of training records: \" + str(len(train_data)))\nprint(\"Number of testing records : \" + str(len(test_data)))\nprint(\"Number of scoring records : \" + str(len(score_data)))\n"
        }, 
        {
            "source": "As you can see our data has been successfully split into the following data sets: \n\n-  The train data set, which is the largest group, is used for training.\n-  The test data set will be used for model evaluation and is used to test the assumptions of the model.\n-  The score data set will be used for scoring in the cloud.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### 3.2: Create a pipeline and train a model", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "In this section you will create scikit-learn machine learning pipeline and then train the model.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "In the first step you need to import the scikit-learn machine learning packages that will be needed in the subsequent steps.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "from sklearn.pipeline import Pipeline\nfrom sklearn import preprocessing\nfrom sklearn import svm, metrics"
        }, 
        {
            "source": "Standardize features by removing the mean and scaling to unit variance.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "scaler = preprocessing.StandardScaler()"
        }, 
        {
            "source": "Next, define estimators you want to use for classification. Support Vector Machines with radial basis function as kernel is used in the following example.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "clf = svm.SVC(kernel='rbf')"
        }, 
        {
            "source": "Let's build the pipeline now. A pipeline consists of transformers and an estimator.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "pipeline = Pipeline([('scaler', scaler), ('svc', clf)])"
        }, 
        {
            "source": "Now, you can train your Random Forest model by using the previously defined **pipeline** and **train data**.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "model = pipeline.fit(train_data, train_labels)"
        }, 
        {
            "source": "You can check your **model quality** now. To evaluate the model, use the **test data**.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "predicted = model.predict(test_data)\n\nprint(\"Evaluation report: \\n\\n%s\" % metrics.classification_report(test_labels, predicted))"
        }, 
        {
            "source": "You can tune your model now to achieve better accuracy. For the sake of simplicity, in this example the tuning section is omitted.", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "<a id=\"persistence\"></a>\n## 4. Persist the model", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "In this section you will learn how to store your pipeline and model in the Watson Machine Learning repository by using python client libraries.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "First, you must import client libraries.", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "from repository.mlrepositoryclient import MLRepositoryClient\nfrom repository.mlrepositoryartifact import MLRepositoryArtifact\nfrom repository.mlrepository import MetaProps, MetaNames"
        }, 
        {
            "source": "Authenticate to Watson Machine Learning service on Bluemix.", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "**Action**: Put authentication information from your instance of Watson Machine Learning service here.</div>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "service_path = 'https://ibm-watson-ml.mybluemix.net'\nusername = '***'\npassword = '***'\ninstance_id = '***'"
        }, 
        {
            "source": "**Tip**: The `service_path`, `username`, and `password` values can be found on the **Service Credentials** tab of the service instance that you created in Bluemix.", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "ml_repository_client = MLRepositoryClient(service_path)\nml_repository_client.authorize(username, password)"
        }, 
        {
            "source": "Create the model artifact (abstraction layer).", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "props = MetaProps({MetaNames.AUTHOR_NAME:\"IBM\", MetaNames.AUTHOR_EMAIL:\"ibm@ibm.com\"})"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "model_artifact = MLRepositoryArtifact(model, name=\"Hand-written digits recognition\", meta_props=props)"
        }, 
        {
            "source": "**Tip**: The `MLRepositoryArtifact` method expects a trained model object, training data, and a model name. (It is this model name that is displayed by the Watson Machine Learning service).", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### 4.1: Save the pipeline and model", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "In this subsection you will learn how to save the pipeline and model artifacts to your Watson Machine Learning instance.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "saved_model = ml_repository_client.models.save(model_artifact)"
        }, 
        {
            "source": "Retrieve the saved model metadata from Watson Machine Learning.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "**Tip**: Use the `meta.available_props()` method to get the list of available props.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "saved_model.meta.available_props()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "print(\"modelType: \" + saved_model.meta.prop(\"modelType\"))\nprint(\"runtime: \" + saved_model.meta.prop(\"runtime\"))\nprint(\"creationTime: \" + str(saved_model.meta.prop(\"creationTime\")))\nprint(\"modelVersionHref: \" + saved_model.meta.prop(\"modelVersionHref\"))"
        }, 
        {
            "source": "**Tip**: The **modelVersionHref** variable is our model unique indentifier in the Watson Machine Learning repository.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### 4.2: Load the model", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "In this subsection you will learn how to load back the saved model from a specified instance of Watson Machine Learning.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "loadedModelArtifact = ml_repository_client.models.get(saved_model.uid)"
        }, 
        {
            "source": "You can print the model name to make sure that model has been loaded correctly.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "print(loadedModelArtifact.name)\nprint(saved_model.uid)"
        }, 
        {
            "source": "As you can see the name is correct. You have already learned how to save and load the model from the Watson Machine Learning repository.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id=\"visualization\"></a>\n## 5. Predict locally and visualize", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "In this section you will learn how to score test data by using the loaded model and visualize the prediction results by using the `plotly` package.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### 5.1: Make local prediction using previously loaded model and score data", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "In this subsection you will score the `predict_data` data set.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "predictions = loadedModelArtifact.model_instance().predict(score_data)"
        }, 
        {
            "source": "To print the prediction results, run the following code:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "print(predictions)"
        }, 
        {
            "source": "### 5.2: Sample visualization of data with the `matplotlib` package", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "images_and_predictions = list(zip(digits.images[int(0.9*samples_count): ], predictions))\nfor i, (image, prediction) in enumerate(images_and_predictions[:4]):\n    plt.subplot(2, 4, i + 5)\n    plt.axis('off')\n    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n    plt.title('Prediction: %i' % prediction)"
        }, 
        {
            "source": "<a id=\"scoring\"></a>\n## 6. Deploy and score in the cloud", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "In this section you will learn how to create online scoring and to score a new data record by using the Watson Machine Learning REST API. \nFor more information about REST APIs, see the [Swagger Documentation](http://watson-ml-api.mybluemix.net/).", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "To work with the Watson Machine Leraning REST API you must generate an access token. To do that you can use the following sample code:", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "import urllib3, requests, json\n\nheaders = urllib3.util.make_headers(basic_auth='{}:{}'.format(username, password))\nurl = '{}/v3/identity/token'.format(service_path)\nresponse = requests.get(url, headers=headers)\nmltoken = json.loads(response.text).get('token')"
        }, 
        {
            "source": "### 6.1: Create the model deployment", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Retrieve the `published_models` URL from the instance details.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#### Get instance details", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "endpoint_instance = service_path + \"/v3/wml_instances/\" + instance_id\nheader = {'Content-Type': 'application/json', 'Authorization': mltoken}\n\nresponse_get_instance = requests.get(endpoint_instance, headers=header)\nprint(response_get_instance)\nprint(response_get_instance.text)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "endpoint_published_models = json.loads(response_get_instance.text).get('entity').get('published_models').get('url')\n\nprint(endpoint_published_models)"
        }, 
        {
            "source": "Execute the following sample code that uses the `published_models` endpoint to get the deployments URL.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#### Get the list of published models", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "header = {'Content-Type': 'application/json', 'Authorization': mltoken}\nresponse_get = requests.get(endpoint_published_models, headers=header)\n\nprint(response_get)\nprint(response_get.text)"
        }, 
        {
            "source": "#### Get the published model deployment URL", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "[endpoint_deployments] = [x.get('entity').get('deployments').get('url') for x in json.loads(response_get.text).get('resources') if x.get('metadata').get('guid') == saved_model.uid]\n\nprint(endpoint_deployments)"
        }, 
        {
            "source": "#### Create an online deployment for the published model", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "payload_online = {\"name\": \"Hand written digits recognition\", \"description\": \"Hand Written Digits Deployment\", \"type\": \"online\"}\nresponse_online = requests.post(endpoint_deployments, json=payload_online, headers=header)\n\nprint(response_online)\nprint(response_online.text)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "scoring_url = json.loads(response_online.text).get('entity').get('scoring_url')\n\nprint(scoring_url)"
        }, 
        {
            "source": " Now, you can send (POST) new scoring records (new data) for which you would like to get predictions. To do that, execute the following sample code: ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "digit = list(digits.data[1])\ndigit2 = list(digits.data[2])"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "payload_scoring = {\"values\": [digit, digit2]}\nprint(payload_scoring)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "response_scoring = requests.post(scoring_url, json=payload_scoring, headers=header)\n\nprint(response_scoring.text)"
        }, 
        {
            "source": "As we can see we predict that hand-written digits are: 1 and 2.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id=\"summary\"></a>\n## 7. Summary and next steps     ", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": " You successfully completed this notebook! You learned how to use scikit-learn machine learning as well as Watson Machine Learning for model creation and deployment. Check out our [Online Documentation](https://console.ng.bluemix.net/docs/services/PredictiveModeling/index.html?pos=2) for more samples, tutorials, documentation, how-tos, and blog posts. ", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "<a id=\"citations\"></a>\n### Citations\n\n[Scikit-learn: Machine Learning in Python](http://jmlr.csail.mit.edu/papers/v12/pedregosa11a.html), Pedregosa et al., JMLR 12, pp. 2825-2830, 2011\n\n[API design for machine learning software: experiences from the scikit-learn project](https://arxiv.org/abs/1309.0238), Buitinck et al., 2013.\n\n\n### Authors\n\n**Lukasz Cmielowski**, PhD, is a Automation Architect and Data Scientist in IBM with a track record of developing enterprise-level applications that substantially increases clients' ability to turn data into actionable knowledge.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Copyright \u00a9 2017 IBM. This notebook and its source code are released under the terms of the MIT License.", 
            "cell_type": "markdown", 
            "metadata": {}
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 (Experimental) with Spark 2.0", 
            "name": "python3-spark20", 
            "language": "python"
        }, 
        "language_info": {
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }, 
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.2", 
            "name": "python", 
            "pygments_lexer": "ipython3"
        }
    }, 
    "nbformat_minor": 1
}